{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWSJpsyKqHjH",
        "outputId": "fe708519-c98d-4d9e-d7c2-5e066968c448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh97t6AIPDD7",
        "colab_type": "text"
      },
      "source": [
        "###Here I had trouble unzipping the the folder programmatically, so I had to unzip it from my google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XDg9OBaYqRMd",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "!mkdir test/test\n",
        "# local_zip = '/content/drive/My Drive/RuTanks7000_v1.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# zip_ref.extractall('/content/drive/My Drive/')\n",
        "# zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLvzq-SqHvIM",
        "colab_type": "text"
      },
      "source": [
        "###Things that I did:\n",
        "- I removed the civilian car class from the input\n",
        "- I created local directories for storing the trained models and trained weights\n",
        "- Tried using sigmoid instead of softmax but didn't improve anything since this is a multi-class classification problem, so I changed it back.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JZynmO0L8UD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.applications import NASNetLarge\n",
        "from keras import models, layers, optimizers, backend\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "base_dir = '/content/drive/My Drive/RuTanks7000_v1'\n",
        "\n",
        "def main():\n",
        "    start = timer()\n",
        "    level1()  # Training the classifier only\n",
        "    level2()  # Training the pretrained model + the trained classifier from level 1\n",
        "    end = timer()\n",
        "    print(\"Time elapsed in minutes: \", ((end - start)/60))\n",
        "\n",
        "# Setting Parameters ##################################################################\n",
        "# image settings\n",
        "img_height,img_width = 331, 331  # For NASNetLarge\n",
        "\n",
        "# classes\n",
        "classnames = [\"Background\", \"BMP2\", \"Buk-M1-2\", \"T14\", \"T90\", \"ZSU23\"]\n",
        "classes = len(classnames)\n",
        "\n",
        "nbrTrainImages = 7000  # per class\n",
        "nbrTestImages = 0  # Value gets accurate after counting (Total Number of test images)\n",
        "\n",
        "!mkdir trained_models\n",
        "!mkdir trained_models/trained_weights\n",
        "!mkdir logs\n",
        "\n",
        "# path = '/content/drive/My Drive/'\n",
        "# dataset_path = '/content/drive/My Drive/RuTanks7000_v1'\n",
        "# weights_path = '/content/drive/My Drive/trained_models/trained_weights'\n",
        "# model_path =  '/content/drive/My Drive/trained_models'\n",
        "# TensorBoardLogDir = '/content/drive/My Drive/logs'\n",
        "\n",
        "path = '/content/drive/My Drive/'\n",
        "dataset_path = '/content/drive/My Drive/RuTanks7000_v1'\n",
        "weights_path = '/content/trained_models/trained_weights/weights_temp.h5'\n",
        "model_path =  '/content/trained_models/trained_models'\n",
        "TensorBoardLogDir = '/content/logs'\n",
        "\n",
        "\n",
        "for ImagesClass in os.listdir(base_dir + '/test/'):\n",
        "    nbrTestImages += len(os.listdir(base_dir + '/test/' + ImagesClass))\n",
        "\n",
        "# unfreezing the base network up to a specific layer in Level2:\n",
        "freezeUptoLayer = \"normal_add_1_15\"   # NASNetLarge\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 0.0002  # Learning_rate in Level 2 = learning_rate/10\n",
        "lr_decay = 0.0001\n",
        "batch = 64\n",
        "fcLayer1 = 32\n",
        "dropout = 0.5\n",
        "\n",
        "epochsL1 = 10\n",
        "patiencel1 = 1\n",
        "factorL1 = 0.5\n",
        "\n",
        "epochsL2 = 10\n",
        "patiencel2 = 1\n",
        "factorL2 = 0.5\n",
        "\n",
        "verbose_train = 1\n",
        "\n",
        "# datagenerators https://keras.io/preprocessing/image/\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir +'/train',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch,\n",
        "    shuffle=True,\n",
        "    classes=classnames,\n",
        "    class_mode='categorical')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    base_dir +'/test',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    classes=classnames,\n",
        "    class_mode='categorical')\n",
        "#########################################################################################\n",
        "\n",
        "# function to plot results of model performance\n",
        "def plot(h,t,e):\n",
        "    history_dict = h[0]\n",
        "    loss_values = history_dict['loss']\n",
        "    validation_loss_values = history_dict['val_loss']\n",
        "    acc_values = history_dict['acc']\n",
        "    validation_acc_values = history_dict['val_acc']\n",
        "    epochs_range = range(1, e + 1)\n",
        "\n",
        "    # Plotting Training and Validation loss of the corresponding Model\n",
        "    plt.plot(epochs_range, loss_values, 'bo', label='Training loss')\n",
        "    plt.plot(epochs_range, validation_loss_values, 'ro', label='Validation loss')\n",
        "    plt.title('Training and validation loss of ' + t)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.yticks(np.arange(0, 3.1, step=0.2))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting Training and Validation accuracy of the corresponding Model\n",
        "    plt.plot(epochs_range, acc_values, 'bo', label='Training accuracy')\n",
        "    plt.plot(epochs_range, validation_acc_values, 'ro', label='Validation accuracy')\n",
        "    plt.title('Training and validation accuracy of ' + t)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.yticks(np.arange(0.3, 1.1, step=0.1))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# LEVEL1 - Training of densely connected layers\n",
        "def level1():\n",
        "    # Building the model using the pretrained model\n",
        "    conv_base1 = NASNetLarge(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "    print(\"\\n### LEVEL1 ###\\npretrained network:\")\n",
        "    conv_base1.summary()\n",
        "    model = models.Sequential()\n",
        "    model.add(conv_base1)\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "    model.add(layers.Dense(fcLayer1, activation='relu'))\n",
        "    model.add(layers.Dropout(dropout))\n",
        "    model.add(layers.Dense(classes, activation='softmax'))\n",
        "\n",
        "    # freezing the base network\n",
        "    print(\"trainable layers bevor freezing:\", int(len(model.trainable_weights)/2)) # weights = weights + bias = 2 pro layer\n",
        "    conv_base1.trainable = False\n",
        "    print(\"trainable layers after freezing:\", int(len(model.trainable_weights)/2))\n",
        "    print(\"\\npretrained network + densely connected classifier\")\n",
        "    model.summary()\n",
        "\n",
        "    # training the added layers only\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=learning_rate, decay=lr_decay), metrics=['acc'])\n",
        "\n",
        "    callbacks_list_L1 = [ModelCheckpoint(filepath=weights_path, save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True),\n",
        "                      ReduceLROnPlateau(monitor='val_acc', factor=factorL1, patience=patiencel1, verbose=1),\n",
        "                      TensorBoard(log_dir=TensorBoardLogDir+'\\\\level1')]\n",
        "\n",
        "    print(\"\\n### Level1 Training ... \")\n",
        "    # training the model\n",
        "    history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch= 1 // batch,\n",
        "        epochs=epochsL1,\n",
        "        callbacks=callbacks_list_L1,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=nbrTestImages,\n",
        "        verbose=verbose_train)\n",
        "\n",
        "    history_val1 = [history.history]  # saving all results of the final test\n",
        "    plot(history_val1, \"LEVEL1:\", epochsL1)\n",
        "    print(\"\\n### LEVEL1 Training finished successfully ###\")\n",
        "\n",
        "    print(\"\\nLoading trained weights from \" + weights_path + \" ...\")\n",
        "    model.load_weights(weights_path)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=learning_rate), metrics=['acc'])\n",
        "    print(\"\\n### Saving Level1 Model to \", model_path+'l1.h5', \" ... \")\n",
        "    model.save(model_path+'l1.h5')\n",
        "\n",
        "\n",
        "# LEVEL2 - Training pretrained network and trained densely connected layers\n",
        "def level2():\n",
        "    # Destroying the current TF graph - https://keras.io/backend/\n",
        "    backend.clear_session()\n",
        "    print(\"\\n### LEVEL2 ###\")\n",
        "    conv_base2 = NASNetLarge(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "    model2 = models.Sequential()\n",
        "    model2.add(conv_base2)\n",
        "    model2.add(layers.GlobalAveragePooling2D())\n",
        "    model2.add(layers.Dense(fcLayer1, activation='relu'))\n",
        "    model2.add(layers.Dropout(dropout))\n",
        "    model2.add(layers.Dense(classes, activation='softmax'))\n",
        "\n",
        "    print(\"\\nLoading trained weights from \" + weights_path + \" ...\")\n",
        "    model2.load_weights(weights_path)\n",
        "\n",
        "    # unfreezing the base network up to a specific layer:\n",
        "    if freezeUptoLayer == \"\":\n",
        "        conv_base2.trainable = True\n",
        "        print (\"\\ntrainable layers: \",int(len(model2.trainable_weights) / 2))\n",
        "    else:\n",
        "        print(\"\\ntrainable layers before unfreezing the base network up to \" + freezeUptoLayer + \": \",int(len(model2.trainable_weights) / 2))  # weights = weights + bias = 2 pro layer\n",
        "        conv_base2.trainable = True\n",
        "        set_trainable = False\n",
        "        for layer in conv_base2.layers:\n",
        "            if layer.name == freezeUptoLayer: set_trainable = True\n",
        "            if set_trainable: layer.trainable = True\n",
        "            else: layer.trainable = False\n",
        "        print(\"trainable layers after the base network unfreezed from layer \" + freezeUptoLayer + \": \", int(len(model2.trainable_weights)/2))\n",
        "\n",
        "    print(\"\\nLEVEL2 Model after unfreezing the base network\")\n",
        "    model2.summary()\n",
        "    model2.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=learning_rate/10, decay=lr_decay), metrics=['acc'])\n",
        "    print (\"\\n### Validating ... \")\n",
        "\n",
        "    val_loss, val_acc = model2.evaluate_generator(test_generator, steps=nbrTestImages, verbose=0)\n",
        "    print('Validation Results before training unfreeze layers and trained densely connected layers:\\nValidation loss:',val_loss,\",\",'Validation accuracy:', val_acc, \"\\n\")\n",
        "\n",
        "    # Jointly training both the unfreeze layers and the added trained densely connected layers\n",
        "    callbacks_list_L2 = [ModelCheckpoint(filepath=model_path+'l2.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True),\n",
        "                      ReduceLROnPlateau(monitor='val_acc', factor=factorL2, patience=patiencel2, verbose=1),\n",
        "                      TensorBoard(log_dir=TensorBoardLogDir+'\\\\level2')]\n",
        "\n",
        "    print (\"\\n### Level2 Training ... \")\n",
        "    history = model2.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=(nbrTrainImages * classes) // batch,\n",
        "        epochs=epochsL2,\n",
        "        callbacks=callbacks_list_L2,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=nbrTestImages,\n",
        "        verbose=verbose_train)\n",
        "\n",
        "    history_val2 = [history.history]  # saving all results of the final test\n",
        "    plot(history_val2, \"LEVEL2:\", epochsL2)\n",
        "    print(\"\\n###LEVEL2 Training finished successfully ###\")\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}