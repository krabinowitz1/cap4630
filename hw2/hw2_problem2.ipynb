{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2_problem2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt44vyY1xW9b",
        "colab_type": "text"
      },
      "source": [
        "# MNIST fashion data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l34GNy7tyNks",
        "colab_type": "text"
      },
      "source": [
        "## Loading the MNIST fashion data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSJyddqGexl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC5iBT_0OCSl",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inugSPsZNytV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA975wHjOJI-",
        "colab_type": "text"
      },
      "source": [
        "#Example of model that fits the data well\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX6SGTpMOIKN",
        "colab_type": "code",
        "outputId": "9c896c5b-7ed6-4347-e517-242b694c779a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "# set up the layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "     keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "epochs = 30\n",
        "history = model.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,  \n",
        "                      validation_data=(test_images, test_labels))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.5010 - acc: 0.8227 - val_loss: 0.4344 - val_acc: 0.8431\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3730 - acc: 0.8658 - val_loss: 0.3976 - val_acc: 0.8579\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3354 - acc: 0.8778 - val_loss: 0.3679 - val_acc: 0.8645\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3129 - acc: 0.8836 - val_loss: 0.3517 - val_acc: 0.8726\n",
            "Epoch 5/30\n",
            "40032/60000 [===================>..........] - ETA: 1s - loss: 0.2923 - acc: 0.8917"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-5c2017bba11f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                       \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                       validation_data=(test_images, test_labels))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqbGdV6oXEyP",
        "colab_type": "text"
      },
      "source": [
        "## Training/test loss/accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b5OCE5YTrEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "test_loss_values = history_dict['val_loss']\n",
        "epochs_range = range(1, epochs+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y98AOblYT3Pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.plot(epochs_range, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, test_loss_values, 'ro', label='Test loss')\n",
        "plt.title('Training and test loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "790AkDaTWuZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_values = history_dict['acc']\n",
        "test_acc_values = history_dict['val_acc']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BkIfPQ4W39E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs_range, acc_values, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs_range, test_acc_values, 'ro', label='Test accuracy')\n",
        "plt.title('Training and test accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRFfzm9a6qoA",
        "colab_type": "text"
      },
      "source": [
        "#Example of model that underfits the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgXJ_noi6w24",
        "colab_type": "code",
        "outputId": "d51653d9-2ba5-4e69-f4fc-e86d5f308805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# set up the layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "epochs = 10\n",
        "history = model.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,  \n",
        "                      validation_data=(test_images, test_labels))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.6043 - acc: 0.7957 - val_loss: 0.5065 - val_acc: 0.8278\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4627 - acc: 0.8420 - val_loss: 0.4733 - val_acc: 0.8364\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4356 - acc: 0.8493 - val_loss: 0.4617 - val_acc: 0.8406\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4231 - acc: 0.8539 - val_loss: 0.4600 - val_acc: 0.8394\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4134 - acc: 0.8575 - val_loss: 0.4502 - val_acc: 0.8433\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4072 - acc: 0.8594 - val_loss: 0.4452 - val_acc: 0.8440\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4014 - acc: 0.8612 - val_loss: 0.4425 - val_acc: 0.8464\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3981 - acc: 0.8608 - val_loss: 0.4536 - val_acc: 0.8432\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3942 - acc: 0.8631 - val_loss: 0.4673 - val_acc: 0.8391\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3919 - acc: 0.8638 - val_loss: 0.4456 - val_acc: 0.8449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCr7WIoM7etD",
        "colab_type": "text"
      },
      "source": [
        "## Training/test loss/accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3KUSkwv7f_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "test_loss_values = history_dict['val_loss']\n",
        "epochs_range = range(1, epochs+1)\n",
        "\n",
        "plt.plot(epochs_range, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, test_loss_values, 'ro', label='Test loss')\n",
        "plt.title('Training and test loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o70JWbDA7uP_",
        "colab": {}
      },
      "source": [
        "acc_values = history_dict['acc']\n",
        "test_acc_values = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs_range, acc_values, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs_range, test_acc_values, 'ro', label='Test accuracy')\n",
        "plt.title('Training and test accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12bIMzJX-DSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_values = history_dict['acc']\n",
        "test_acc_values = history_dict['val_acc']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOlHEzdH-Fng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs_range, acc_values, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs_range, test_acc_values, 'ro', label='Test accuracy')\n",
        "plt.title('Training and test accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ1jPV-iaQKt",
        "colab_type": "text"
      },
      "source": [
        "#Example of model that overfits the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlFsp18zbMUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up the layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "epochs = 20\n",
        "history = model.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,  \n",
        "                      validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F_HO5J0bWEM",
        "colab_type": "text"
      },
      "source": [
        "##Training/test loss/accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb1CosAXbXST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "test_loss_values = history_dict['val_loss']\n",
        "epochs_range = range(1, epochs+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkNygrGAba6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs_range, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, test_loss_values, 'ro', label='Test loss')\n",
        "plt.title('Training and test loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V36JC-Pibc2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_values = history_dict['acc']\n",
        "test_acc_values = history_dict['val_acc']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "komcgHMTbebo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs_range, acc_values, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs_range, test_acc_values, 'ro', label='Test accuracy')\n",
        "plt.title('Training and test accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}